{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOm8BTlU57Sm"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite' #same as integer8  hardware deployable model...also called quantised  hardware deployable model\n",
        "MODEL_TFLITE = MODELS_DIR + \"model.tflite\" #same as floating point hardware deployable model ...also called non-quantised  hardware deployable model\n",
        "\n",
        "\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model_tflite.cc'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "JbLbuLwf6DLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "BUbaiYgj6E5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's download the dataset from UCI\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "\n",
        "#columns don't come named, so these are the names for use\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "#turn it into a Pandas Dataset\n",
        "dataset = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)"
      ],
      "metadata": {
        "id": "DOO76IY-6FS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop nulls\n",
        "dataset = dataset.dropna()\n",
        "\n",
        "#train / test split\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=seed)\n",
        "test_dataset = dataset.drop(train_dataset.index)\n",
        "\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "\n",
        "#MPG is our target\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')\n",
        "\n",
        "#select only the Horsepower column\n",
        "#train_features = np.array(train_features['Horsepower'])\n",
        "#test_features = np.array(test_features['Horsepower'])\n",
        "reject1 = train_features.pop('Model Year')\n",
        "reject2 = train_features.pop('Origin')\n",
        "reject1 = test_features.pop('Model Year')\n",
        "reject2 = test_features.pop('Origin')\n",
        "\n",
        "\n",
        "train_features = np.array(train_features)\n",
        "test_features = np.array(test_features)\n",
        "test_features_ = np.zeros(test_features.shape)\n",
        "train_features_ = np.zeros(train_features.shape)\n",
        "train_labels_ = np.zeros(train_labels.shape)\n",
        "test_labels_ = np.zeros(test_labels.shape)\n",
        "\n",
        "#Feature Scaling\n",
        "for i in range(5):\n",
        "  max = np.max(train_features[:,i]);\n",
        "  min = np.min(train_features[:,i]);\n",
        "  train_features_[:,i] = (train_features[:,i] - min)/(max-min);\n",
        "train_features = train_features_;\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  max = np.max(test_features[:,i]);\n",
        "  min = np.min(test_features[:,i]);\n",
        "  test_features_[:,i] = (test_features[:,i] - min)/(max-min);\n",
        "test_features = test_features_;\n",
        "\n",
        "\n",
        "max = np.max(train_labels);\n",
        "min = np.min(train_labels);\n",
        "train_labels_ = (train_labels - min)/(max-min);\n",
        "max = np.max(test_labels);\n",
        "min = np.min(test_labels);\n",
        "test_labels_ = (test_labels - min)/(max-min);\n",
        "train_labels = train_labels_;\n",
        "test_labels = test_labels_;\n",
        "\n",
        "\n",
        "print(test_features_[13])\n",
        "print(test_labels_[13])\n",
        "print(train_features[34])\n",
        "print(train_labels[34])\n",
        "\n",
        "plt.plot(train_features, train_labels, 'b.', label='Actual values')"
      ],
      "metadata": {
        "id": "xudNw9yH6FWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "#only takes one feature\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(5,)))\n",
        "model.add(keras.layers.Dense(16, activation='relu'))\n",
        "#only one output\n",
        "model.add(keras.layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=1000, batch_size=64,\n",
        "                    validation_data=(test_features, test_labels))\n",
        "\n",
        "\n",
        "\n",
        "# Save the model to disk\n",
        "model.save(MODEL_TF)"
      ],
      "metadata": {
        "id": "PJ1Dz_PB6FZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index=4;\n",
        "print(test_features[4])\n",
        "model.predict(test_features[[4]])"
      ],
      "metadata": {
        "id": "0Exac88j6Fb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting loss over our epochs\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "\n",
        "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ],
      "metadata": {
        "id": "vC_6ckfy6SAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "test_loss, test_mae = model.evaluate(test_features, test_labels)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "y_test_pred = model.predict(test_features)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(test_features, test_labels, 'b.', label='Actual values')\n",
        "plt.plot(test_features, y_test_pred, 'r.', label='TF predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S7XPdeUK6SDg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}